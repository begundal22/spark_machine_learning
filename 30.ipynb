{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wtVyhDhewWki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2ef7e1-313e-493f-becf-77e9661e32a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=3eda3959eebacf6d44abd747bda0fd4f89d381ee7761ee7afa5b0d80550a3f32\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession, SQLContext\n",
        "spark = SparkSession.builder.appName('Movie Lens Recommendation').getOrCreate()"
      ],
      "metadata": {
        "id": "vtresTBPpGsm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import Row\n",
        "\n",
        "lines = spark.read.text(\"/content/ratings.dat\").rdd\n",
        "parts = lines.map(lambda row: row.value.split(\"::\"))\n",
        "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
        "                                     rating=int(p[2]), timestamp=int(p[3])))\n",
        "ratings = spark.createDataFrame(ratingsRDD)\n",
        "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Build the recommendation model using ALS on the training data\n",
        "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
        "model = als.fit(training)\n",
        "\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test)\n",
        "predictions.show()\n",
        "\n",
        "import math\n",
        "result = predictions.rdd.map(lambda row: row['prediction'] - row['rating']).map(lambda x: x*x).filter(lambda x: not math.isnan(x))\n",
        "mse = result.reduce(lambda x,y: x+y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBWTqvoFpmgc",
        "outputId": "0cfbbee9-4aed-492b-e87a-4b1eb0ac9681"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+---------+----------+\n",
            "|userId|movieId|rating|timestamp|prediction|\n",
            "+------+-------+------+---------+----------+\n",
            "|     1|    260|     4|978300760| 3.9904704|\n",
            "|     1|    531|     4|978302149|  3.693758|\n",
            "|     1|   1029|     5|978302205| 3.8508663|\n",
            "|     1|   1197|     3|978302268| 3.9899428|\n",
            "|     1|   1207|     4|978300719| 5.2481565|\n",
            "|     1|   1246|     4|978302091| 4.4040008|\n",
            "|     1|   1270|     5|978300055|  4.077993|\n",
            "|     1|   1907|     4|978824330| 3.8529975|\n",
            "|     1|   2018|     4|978301777| 4.2558813|\n",
            "|     1|   2355|     5|978824291| 4.0124564|\n",
            "|     1|   2687|     3|978824268| 3.6171255|\n",
            "|     1|   2692|     4|978301570| 4.1419935|\n",
            "|     1|   2804|     5|978300719|  4.344903|\n",
            "|     1|   3186|     4|978300019|  5.009645|\n",
            "|     1|   3408|     4|978300275|  4.161335|\n",
            "|     2|    265|     4|978299026| 3.3188462|\n",
            "|     2|    292|     3|978300123| 3.3927314|\n",
            "|     2|    498|     3|978299418| 1.6427406|\n",
            "|     2|    589|     4|978299773| 4.0933514|\n",
            "|     2|    780|     3|978299966| 3.6674998|\n",
            "+------+-------+------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S3b9lHvNqVgz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}